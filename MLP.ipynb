{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyPkAHpwcmf/14vZtBAigdf0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Series-Parallel/UCR_Time_Series_Classification_Deep_Learning_From_Scratch/blob/main/MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightning > /dev/null"
      ],
      "metadata": {
        "id": "6JtlO9Nhg2dn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHwvi1QqBzEG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import lightning as L\n",
        "from lightning.pytorch.callbacks import ModelCheckpoint\n",
        "from lightning.pytorch.callbacks import Callback\n",
        "\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.optim import Adadelta\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def reducer(filename):\n",
        "  data = np.loadtxt(filename, delimiter=',')\n",
        "  Y = data[:,0]\n",
        "  X = data[:,1:]\n",
        "  return X, Y"
      ],
      "metadata": {
        "id": "f6_badq7N7jA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = reducer(\"Adiac_TRAIN.txt\")\n",
        "x_test, y_test = reducer(\"Adiac_TEST.txt\")"
      ],
      "metadata": {
        "id": "I0CBSWoQOaOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = len(np.unique(y_test))"
      ],
      "metadata": {
        "id": "rpKBxnPGPDnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "normalizing the labels"
      ],
      "metadata": {
        "id": "ggCHopFiS6h6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = ((y_train - y_train.min())/(y_train.max() - y_train.min()) * (classes - 1)).astype(int)\n",
        "y_test = ((y_test - y_test.min())/ (y_test.max() - y_test.min()) * (classes - 1)).astype(int)"
      ],
      "metadata": {
        "id": "lP4XnOmOPZFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)"
      ],
      "metadata": {
        "id": "RS_OFMIOi7iI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_mean = x_train.mean()\n",
        "x_train_std = x_train.std()\n",
        "x_train = (x_train - x_train_mean) / x_train_std\n",
        "x_test = (x_test - x_train_mean) / x_train_std"
      ],
      "metadata": {
        "id": "ft7WrxjgjaN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_train = torch.tensor(x_train, dtype=torch.float32)\n",
        "input_test = torch.tensor(x_test, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "E9-iVAX8jtDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TensorDataset(input_train, y_train_tensor)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)"
      ],
      "metadata": {
        "id": "_uEKj7IakMVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = TensorDataset(input_test, y_test_tensor)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=16)"
      ],
      "metadata": {
        "id": "zP5SKqitx4k9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(L.LightningModule):\n",
        "\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super().__init__()\n",
        "\n",
        "    L.seed_everything(813306)\n",
        "\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Dropout(0.1),\n",
        "        nn.Linear(input_dim, 500),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2),\n",
        "        nn.Linear(500, 500),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2),\n",
        "        nn.Linear(500, 500),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.3),\n",
        "        nn.Linear(500, output_dim)\n",
        "      )\n",
        "\n",
        "    self.loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.model(x)\n",
        "\n",
        "  def training_step(self, batch, batch_size):\n",
        "    x, y = batch\n",
        "    logits = self(x)\n",
        "    loss = self.loss_fn(logits, y)\n",
        "    self.log(\"train_loss\", loss)\n",
        "    return loss\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    x, y = batch\n",
        "    logits = self(x)\n",
        "    val_loss = self.loss_fn(logits, y)\n",
        "    acc = (torch.argmax(logits, dim=1) == y).float().mean()\n",
        "    self.log('val_loss', val_loss, prog_bar=True)\n",
        "    self.log('val_acc', acc, prog_bar=True)\n",
        "    return {\"val_loss\": val_loss, \"val_acc\": acc}\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    return Adadelta(self.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "iXf40p_0koI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = input_train.shape[1]"
      ],
      "metadata": {
        "id": "1Aas1b1toarN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_dim = len(torch.unique(y_train_tensor))"
      ],
      "metadata": {
        "id": "yAFKx79Soxy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP(input_dim=input_dim, output_dim=output_dim)"
      ],
      "metadata": {
        "id": "monpqld8ozf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_callback = ModelCheckpoint(\n",
        "    monitor='val_loss',   # or use 'val_acc' if you prefer\n",
        "    mode='min',\n",
        "    save_top_k=1,\n",
        "    verbose=True,\n",
        "    filename='best-checkpoint'\n",
        ")"
      ],
      "metadata": {
        "id": "14t39bqayJ2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = L.Trainer(\n",
        "    max_epochs=5000,\n",
        "    callbacks=[checkpoint_callback]\n",
        ")"
      ],
      "metadata": {
        "id": "8jHwm5m-pWS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)"
      ],
      "metadata": {
        "id": "iu6knDv3yS33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = MLP(input_dim, output_dim)\n",
        "best_model.load_state_dict(torch.load(checkpoint_callback.best_model_path)['state_dict'])\n",
        "\n",
        "# Evaluate on test set\n",
        "best_model.eval()\n",
        "with torch.no_grad():\n",
        "    logits = best_model(input_test)\n",
        "    predictions = torch.argmax(logits, dim=1)\n",
        "    accuracy = (predictions == y_test_tensor).float().mean()\n",
        "\n",
        "print(f\"Best Validation Accuracy: {checkpoint_callback.best_model_score.item():.4f}\")\n",
        "print(f\"Test Accuracy (Best Model): {accuracy.item():.4f}\")"
      ],
      "metadata": {
        "id": "IK6pAq48UvBj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}